#version 450

layout (local_size_x = 10, local_size_y = 10, local_size_z = 1) in; // At least 1 for each local size

layout(set = 0, binding = 0) uniform sampler3D volumnSampler; // Stores 3D intensities, [0, 1] * color white, not alpha

layout(set = 0, binding = 1, rgba8) uniform writeonly image2D raycastedImage;

struct Ray
{
	vec3 origin;
	vec3 direction;
};

// Fixed transfer fuction for testing
// Transfer function from ImGUI
// layout(set 0, binding = ...) uniform dynamic sampler4D volumnColor; f(intensity) = color
// layout(set 0, binding = ...) uniform dynamic sampler2D volumnAlpha; f(intensity) = alpha
vec3 toColor(float intensity)
{
	return vec3(intensity, intensity, intensity); // Gray scale
}
float toAlpha(float intensity)
{
	return intensity;
}

vec4 visualizeDirection(int direction) // Return the color for this pixel based on the direction, default is 0
{
	// direction = 0 (default, bottom-up?/top-down?)
	//           = 1 (sideway)
	ivec2 imageDimension = imageSize(raycastedImage);
	ivec3 textureDimension = textureSize(volumnSampler, 0);

	ivec2 pixelLocation = ivec2(gl_GlobalInvocationID.xy); // This pixel location
	vec2 normalizedPixelLocation = pixelLocation / vec2(imageDimension.x - 1, imageDimension.y - 1); // Normalize the pixel location for testing

	// float slide = 40.0f / 112.0f; // [0, 112] slides, normalized to [0.0, 1.0]
	float slide = 0.5f;
	vec4 sampled = texture(volumnSampler, vec3(normalizedPixelLocation, slide)); // U, V, W
	float intensity = sampled.x; // Only the intensity color value is recorded in the first component
	return vec4(intensity, intensity, intensity, 1.0f);
}

void main()
{
	// Orthographic projection, with the box dimension beside its depth equals to the image dimension

	// Raycasted image
	// ivec2 localInvocXY = ivec2(gl_GlobalInvocationID.xy) / imageDimension; // Local invocation x,y?
	const ivec2 pixelViewportLocation = ivec2(gl_GlobalInvocationID.xy); // Pixel location in viewport space

	ivec2 imageDimension = imageSize(raycastedImage); // - ivec2(-1)

	ivec3 textureDimension = textureSize(volumnSampler, 0); // - ivec3(-1)

	const mat2x4 toWorldSpace = mat2x4(vec4(1, 0, 0, 1.0 / imageDimension.x), vec4(0, -1, 0, 0)); // 2 columns, 4 rows, aka 4x2, vec4(pixelViewportLocation.x, -pixelViewportLocation.y, 0.0, 1.0)
	mat4 translate = mat4(1);
	translate[3] = vec4(-imageDimension.x / 2.0, imageDimension.y / 2.0, 0.0, 1.0); // Shift the image's center toward the world origin
	// vec4 pixelWorldLocation = translate * toWorldSpace * pixelViewportLocation;

	vec3 pixelWorldLocation = vec3(pixelViewportLocation.x - ((imageDimension.x - 1) / 2.0), -pixelViewportLocation.y + ((imageDimension.y - 1) / 2), -1.9);
	// pixelWorldLocation = translate * pixelWorldLocation;

	vec3 volumeImageOrigin = vec3(-(imageDimension.x - 1) / 2.0, (imageDimension.y - 1) / 2.0, -1.0);

	// pixel, left edge
	// viewport = (w - 1, h - 1)
	// -> world = ((w - 1) - (w - 1) / 2, -(h - 1) + (h - 1) / 2, -1)
	//    world = ((w - 1) / 2, -(h - 1) / 2, -1)

	// volume origin
	// sample space = (0, 0, 0)
	// -> world = (-(w - 1) / 2, (h - 1) / 2, -1)

	// diff = pixel - volume orgin = ((w - 1), -(h - 1), 0)
	// sample space = abs(diff / ((w - 1), (h - 1), 1)) = abs(1, -1, 0) = (1, 1, 0)

	vec3 diff = pixelWorldLocation - volumeImageOrigin;
	const vec3 samplerLocation = vec3(abs(diff.x / (imageDimension.x - 1)), abs(diff.y / (imageDimension.y - 1)), abs(diff.z));
	vec4 sampled = texture(volumnSampler, samplerLocation);
	float intensity = sampled.x;

	imageStore(raycastedImage, pixelViewportLocation, vec4(intensity, intensity, intensity, 1.0));

//	// Bounding volume box, mapped to the sampled3D [0, 1]^3
//	const ivec3 textureDimension = textureSize(volumnSampler, 0);
//	const uint boxWidth = imageDimension.x;
//	const uint boxHeight = imageDimension.y;
//	const uint boxDepth = 1;
//	const vec4 boxAxisX = vec4(1.0, 0.0, 0.0, 1.0);
//	const vec4 boxAxisY = vec4(0.0, -1.0, 0.0, 1.0);
//	const vec4 boxAxisZ = vec4(0.0, 0.0, -1.0, 1.0);
//	mat4 boxTranslation = mat4(1);
//	boxTranslation[3] = vec4(-boxWidth / 2.0, boxHeight / 2.0, -1.0, 1.0);
//	vec4 boxOrigin = vec4(0.0, 0.0, 0.0, 1.0); // Top left front corner
//	boxOrigin = boxTranslation * boxOrigin;
//
//	const vec3 frontHit = vec3(pixelWorldLocation.xy, -1.0); // Shifted -1.0 in the z direction
//	const vec3 backHit = vec3(pixelWorldLocation.xy, -2.0); // boxDepth
//	const Ray raycast = Ray(frontHit, backHit - frontHit);
//
//	// For this simple ray cast, we don't have to find t and the ray length direction is perserved for scaling
//
//	// t is [0, 1], where 1 == backHit == frontHit + (backHit - frontHit), because of this we don't normalize backHit - frontHit
//	// divide t equally number of samples
//
//	uint samples = 10; // Including t = 0, t = i and t = 1
//	vec4 pixelColor = vec4(0.0);
//	// to sampler coordinate 3D [0, 1]^3
//	vec3 diff = frontHit - boxOrigin.xyz;
//	vec3 samplercoord = vec3(abs(diff.x / imageDimension.x), abs(diff.y/imageDimension.y), abs(diff.z));
//	vec4 sampled = texture(volumnSampler, samplercoord);
//	float intensity = sampled.x;
//	pixelColor = vec4(intensity, intensity, intensity, 1.0);
//
//
//
////	for (float t = 0; t <= 1; t += (1.0 / samples))
////	{
////		// https://en.wikipedia.org/wiki/Exponential_decay
////		const vec3 sampledWordLocation = raycast.origin + (raycast.direction * t);
////		const vec3 samplerLocation = vec3(sampledWordLocation.x / boxWidth, sampledWordLocation.y / boxDepth, abs(sampledWordLocation.z));
////		vec4 sampled = texture(volumnSampler, samplerLocation);
////		float intensity = sampled.x;
////		vec3 sampleColor = toColor(intensity);
////		float sampleAlpha = toAlpha(intensity);
////		pixelColor += vec4(sampleColor, sampleAlpha);
////	}
////
//
//	imageStore(raycastedImage, pixelViewportLocation, pixelColor);
}

// for each pixel assign a flat color then transfer it over to a swapchain image for testing
// then assign the color value each pixel in a descriptor storage buffer

// Have a dummy cube [0, 1]^3, translate into in the world space
// Then have a function which will map this dummy cube to the volumn sampler


// TODO: Orthographic projection, perspective projection later

// augment the uv with world space and the volumnSampler with world space coordinate (x,y,z)
// descriptor of the width and height of the screen (push constant?)
// volume data is passed as a descriptor as well
// f(width_x, height_y) -> world space x, y
// perform ray cast from those x, y
// run the compute shader in parallel each pixel, instead of going through each of them one by one
// TODO: how to present the image in the compute shader after finished ray castingn?

//[[nodiscard]] inline auto getIntensity(std::span<Intensity, NUM_INTENSITIES> slides, int z, int y, int x)
//{
//	return slides[(z * SLIDE_HEIGHT * SLIDE_WIDTH) + (y * SLIDE_WIDTH) + x];
// }

// Bouding volumes with slabs
//hitStruct{ int numroots; float dHitOne; float dHitTwo; }; // d represent the postive scale of the vector, each represent the root
//hitStruct isIntersect(ray, 3 pair of slabs)
//{}
//

